{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35416bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a Client\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from IPython.display import display\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from influxdb_client import InfluxDBClient\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "# parameters to be set (\"optimum\" hyperparameters obtained from grid search):\n",
    "look_back = 38#移动平均长度\n",
    "epochs = 10#迭代多少次\n",
    "batch_size = 32#默认值\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# read data from InfluxDB 2.0 \n",
    "token = \"K2TFepmH-x3a0wHiponbMFvPgg7r3BQv63ET1YqZk4glJOIHunvrw5Yjkj3XxxUaxuIsssjRfO9VA6YclLizEA==\"\n",
    "org = \"CYTEK\"\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token, org=org, debug=False)\n",
    "query_api = client.query_api()\n",
    "data_influxdb = query_api.query_data_frame('from(bucket:\"Xiaoluzi\")'\n",
    "                                        '|> range(start:2023-03-28T01:44:00Z, stop:2023-04-20T07:02:00Z)'\n",
    "                                        '|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")'\n",
    "                                        '|> keep(columns: [\"_power_A\",\"_niv_temperature_A\",\"_power_B\",\"_niv_temperature_B\",\"_time\"])')\n",
    "\n",
    "#delete niv==0\n",
    "data_influxdb=data_influxdb[~data_influxdb['_niv_temperature_A'].isin([0.000])]\n",
    "\n",
    "#interpol 1s\n",
    "temp_data=data_influxdb\n",
    "temp_data.index=pd.to_datetime(temp_data['_time'],unit='s')\n",
    "interpol=interpolate.interp1d(temp_data['_time'], temp_data[\"_niv_temperature_A\"], kind='linear')\n",
    "temp_data['date']=temp_data.index\n",
    "helper = pd.DataFrame({'date': pd.date_range(temp_data.index.min(), temp_data.index.max(),freq='1S')})\n",
    "temp_data2= pd.merge(temp_data, helper, on='date', how='outer').sort_values('date')\n",
    "temp_data2.index=temp_data2['date']\n",
    "temp_data2[\"_niv_temperature_A\"] = temp_data2[\"_niv_temperature_A\"].interpolate(method='linear')\n",
    "temp_data2[\"_niv_temperature_B\"] = temp_data2[\"_niv_temperature_B\"].interpolate(method='linear')\n",
    "temp_data2[\"_power_A\"] = temp_data2[\"_power_A\"].interpolate(method='linear')\n",
    "temp_data2[\"_power_B\"] = temp_data2[\"_power_B\"].interpolate(method='linear')\n",
    "temp_data2=temp_data2[temp_data2['date'].isin(helper['date'])]\n",
    "data_influxdb=temp_data2\n",
    "print(data_influxdb)\n",
    "\n",
    "\n",
    "train_data=pd.DataFrame()\n",
    "train_data['P_and_T_data']=np.reshape(np.array(data_influxdb[['_niv_temperature_A',\"_niv_temperature_B\",'_power_A',\"_power_B\"]]),len(data_influxdb['_niv_temperature_A'])*4)\n",
    "\n",
    "print(train_data['P_and_T_data'])\n",
    "\n",
    "# save train_data values as type of floating point number\n",
    "train_data_tofloat = train_data.P_and_T_data.values.astype('float32')\n",
    "\n",
    "# reshape to column vector\n",
    "train_data_tofloat = train_data_tofloat.reshape(len(train_data_tofloat), 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_tofloat = scaler.fit_transform(train_data_tofloat)\n",
    "\n",
    "# split data into training set and test set\n",
    "train_size = int(len(train_data_tofloat) * 0.67)#2/3用作训练集\n",
    "if train_size%2==1:\n",
    "\ttrain_size+=1\n",
    "test_size = len(train_data_tofloat) - train_size\n",
    "train, test = train_data_tofloat[0:train_size,:], train_data_tofloat[train_size:len(train_data_tofloat),:]\n",
    "\n",
    "print('Split data into training set and test set... Number of training samples/ test samples:', len(train), len(test))\n",
    "# convert an array of values into a time series dataset \n",
    "# in form \n",
    "#                     X                     Y\n",
    "# t-look_back+1, t-look_back+2, ..., t     t+1\n",
    "#print(train.head(10))\n",
    "print(train[0:10])\n",
    "print(train[10:12])\n",
    "print(test)\n",
    "def create_dataset(dataset, look_back):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\tif i%4==0:\n",
    "\t\t\tdataX.append(dataset[i:(i+look_back), 0])\n",
    "\t\t\tdataY.append(dataset[i+look_back:(i+look_back+2), 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "# convert train_data into time series dataset\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input of the LSTM to be format [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "trainY = np.reshape(trainY, (trainY.shape[0], trainY.shape[1], 1))\n",
    "testY = np.reshape(testY, (testY.shape[0], testY.shape[1], 1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 1)))#4 :Positive integer, dimensionality of the output space.\n",
    "model.add(Dense(2),activation='sigmoid')#神经网络层\n",
    "model.compile(loss='mse', optimizer='adam')#MeanSquaredErro #loss y(true)-y(expect)\n",
    "model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size)# batch_size：Number of samples per gradient update.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ebafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\Administrator\\Desktop\\tfmodel\\TABPAB38-03-28-04-20-2023-2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
